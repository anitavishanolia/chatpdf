export const extractData = `The number of bits a computer can store gives an upper limit on the amount of
information it can process. Looking at the number of bits different computers
can store over time gives us a rough indication of how computing power has
increased. Here, we consider two machines: the Apollo Guidance Computer
and a modern laptop.
The Apollo Guidance Computer was developed in the early 1960s to control the
flight systems of the Apollo spacecraft. It might be considered the first personal
computer, since it was designed to be used in real-time by a single operator (an
astronaut in the Apollo capsule). Most earlier computers required a full room,
and were far too expensive to be devoted to a single user; instead, they pro-
cessed jobs submitted by many users in turn. Since the Apollo Guidance Com-
puter was designed to fit in the Apollo capsule, it needed to be small and light.
Its volume was about a cubic foot and it weighed 70 pounds. The AGC was
AGC User Interface the first computer built using integrated circuits, miniature electronic circuits
that can perform simple logical operations such as performing the logical and
of two values. The AGC used about 4000 integrated circuits, each one being able
to perform a single logical operation and costing $1000. The AGC consumed a
significant fraction of all integrated circuits produced in the mid-1960s, and the
project spurred the growth of the integrated circuit industry.
The AGC had 552 960 bits of memory (of which only 61 440 bits were modifiable,
the rest were fixed). The smallest USB flash memory you can buy today (from
SanDisk in December 2008) is the 1 gigabyte Cruzer for $9.99; 1 gigabyte (GB)
is 230 bytes or approximately 8.6 billion bits, about 140 000 times the amount of
memory in the AGC (and all of the Cruzer memory is modifiable). A typical low-
end laptop today has 2 gigabytes of RAM (fast memory close to the processor
that loses its state when the machine is turned off) and 250 gigabytes of hard
disk memory (slow memory that persists when the machine is turned off); for
under $600 today we get a computer with over 4 million times the amount of
memory the AGC had. Moore’s law is a
violation of
Murphy’s law.
Everything gets
better and better.
Gordon Moore
Improving by a factor of 4 million corresponds to doubling just over 22 times.
The amount of computing power approximately doubled every two years be-
tween the AGC in the early 1960s and a modern laptop today (2009). This prop-
erty of exponential improvement in computing power is known as Moore’s Law.
Gordon Moore, a co-founder of Intel, observed in 1965 than the number of com-
ponents that can be built in integrated circuits for the same cost was approxi-
mately doubling every year (revisions to Moore’s observation have put the dou-
bling rate at approximately 18 months instead of one year). This progress has
been driven by the growth of the computing industry, increasing the resources
available for designing integrated circuits. Another driver is that today’s tech-
nology is used to design the next technology generation. Improvement in com-
puting power has followed this exponential growth remarkably closely over the
past 40 years, although there is no law that this growth must continue forever.
Although our comparison between the AGC and a modern laptop shows an im-
pressive factor of 4 million improvement, it is much slower than Moore’s law
would suggest. Instead of 22 doublings in power since 1963, there should have
been 30 doublings (using the 18 month doubling rate). This would produce an
improvement of one billion times instead of just 4 million. The reason is our
comparison is very unequal relative to cost: the AGC was the world’s most ex-
pensive small computer of its time, reflecting many millions of dollars of gov-
ernment funding. Computing power available for similar funding today is well
over a billion times more powerful than the AGC.
`;